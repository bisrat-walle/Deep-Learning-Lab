{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e77dec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886699f",
   "metadata": {},
   "source": [
    "## Activation Functions: ReLu, Sigmoid, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d9e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = torch.maximum(torch.tensor(0, dtype=inputs.dtype), inputs)\n",
    "\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = torch.exp(inputs - torch.max(inputs))\n",
    "        probabilities = exp_values / torch.sum(exp_values)\n",
    "        self.output = probabilities\n",
    "\n",
    "class Activation_Sigmoid:\n",
    "    def forward(self, inputs):\n",
    "        self.output = 1 / (1 + torch.exp(-inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8bc16c",
   "metadata": {},
   "source": [
    "## Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcef3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, n_features, n_neurons):\n",
    "        self.weights = torch.rand((n_features, n_neurons))\n",
    "        self.biases = torch.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs, activation_fun_name):\n",
    "        weighted_sum = torch.matmul(inputs, self.weights) + self.biases\n",
    "        if activation_fun_name == \"relu\":\n",
    "            activation_function = Activation_ReLU()\n",
    "            activation_function.forward(weighted_sum)\n",
    "        elif activation_fun_name == \"sigmoid\":\n",
    "            activation_function = Activation_Sigmoid()\n",
    "            activation_function.forward(weighted_sum)\n",
    "        elif activation_fun_name == \"softmax\":\n",
    "            activation_function = Activation_Softmax()\n",
    "            activation_function.forward(weighted_sum)\n",
    "        else:\n",
    "            raise Exception(\"Unsuppported activation function\")\n",
    "        \n",
    "        self.output = activation_function.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a1533",
   "metadata": {},
   "source": [
    "## Loss: Categorical Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "432df9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossentropy:\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Clip values to avoid log(0) or log(1)\n",
    "        y_pred_clipped = torch.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        log_likelihoods = -torch.sum(y_true * torch.log(y_pred_clipped))\n",
    "        return log_likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e7cf1",
   "metadata": {},
   "source": [
    "## Using ReLU for hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29a503b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: tensor([[1.6324e-15, 0.0000e+00, 1.0000e+00]])\n",
      "Categorical Cross-Entropy Loss: 16.11809539794922\n",
      "Accuracy: tensor([False, False, False])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "input_data = torch.rand((1, 4))\n",
    "\n",
    "# 3 hidden layers\n",
    "layer1 = DenseLayer(4, 18)\n",
    "layer2 = DenseLayer(18, 18)\n",
    "layer3 = DenseLayer(18, 18)\n",
    "# output layer\n",
    "output_layer = DenseLayer(18, 3)\n",
    "\n",
    "# Forward pass\n",
    "layer1.forward(input_data, \"relu\")\n",
    "layer2.forward(layer1.output, \"relu\")\n",
    "layer3.forward(layer2.output, \"relu\")\n",
    "output_layer.forward(layer3.output, \"softmax\")\n",
    "\n",
    "target = torch.tensor([0, 1, 0])\n",
    "\n",
    "# Computing loss\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.forward(output_layer.output, y_true)\n",
    "accuracy = target == torch.argmax(output_layer.output, axis=1)\n",
    "\n",
    "print(\"Final output:\", output_layer.output)\n",
    "print(\"Categorical Cross-Entropy Loss:\", loss.item())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae8c296",
   "metadata": {},
   "source": [
    "## Using Sigmoid for hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d898ea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: tensor([[0.4800, 0.0678, 0.4522]])\n",
      "Categorical Cross-Entropy Loss: 1.5275838375091553\n",
      "Accuracy: tensor([ True, False,  True])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "input_data = torch.rand((1, 4))\n",
    "\n",
    "# 3 hidden layers\n",
    "layer1 = DenseLayer(4, 18)\n",
    "layer2 = DenseLayer(18, 18)\n",
    "layer3 = DenseLayer(18, 18)\n",
    "# output layer\n",
    "output_layer = DenseLayer(18, 3)\n",
    "\n",
    "# Forward pass\n",
    "layer1.forward(input_data, \"sigmoid\")\n",
    "layer2.forward(layer1.output, \"sigmoid\")\n",
    "layer3.forward(layer2.output, \"sigmoid\")\n",
    "output_layer.forward(layer3.output, \"softmax\")\n",
    "\n",
    "target = torch.tensor([0, 1, 0])\n",
    "\n",
    "# Computing loss\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.forward(output_layer.output, y_true)\n",
    "accuracy = target == torch.argmax(output_layer.output, axis=1)\n",
    "\n",
    "print(\"Final output:\", output_layer.output)\n",
    "print(\"Categorical Cross-Entropy Loss:\", loss.item())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
